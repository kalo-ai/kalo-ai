<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "https://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<title>Learning Hatching for Pen-and-Ink Illustration of Surfaces</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link media="all" href="style.css" type="text/css" rel="stylesheet">
<style type="text/css" media="all">
img {
	PADDING-RIGHT: 0px;
	PADDING-LEFT: 10px;
	FLOAT: right;
	PADDING-BOTTOM: 10px;
	PADDING-TOP: 10px
}
#content {
	MARGIN-LEFT: auto;
	WIDTH: expression(document.body.clientWidth > 925? "925px": "auto" );
	MARGIN-RIGHT: auto;
	TEXT-ALIGN: left;
	max-width: 925px
}
body {
	TEXT-ALIGN: center
}
</style>
</head>
<body>
<div id="content">
    <h1 align="center">Learning Hatching for Pen-and-Ink Illustration of Surfaces</h1>
    <img src="ML_Hatching_Teaser.jpg" alt="teaser" align="middle">
  <h2>People</h2>
  <ul id="people">
    <li><a href="https://kalo-ai.github.io/">Evangelos Kalogerakis</a> </li>
    <li><a href="https://www.dgp.toronto.edu/~derek/">Derek Nowrouzezahrai</a></li>
    <li><a href="https://www.dgp.toronto.edu/~breslav">Simon Breslav</a></li>
    <li><a href="https://www.dgp.toronto.edu/%7Ehertzman/">Aaron Hertzmann</a></li>    
  </ul>
  <h2>Abstract</h2>
  <p align="justify">This paper presents an algorithm for learning hatching styles from line drawings. An artist draws a single hatching illustration of a 3D object. Their strokes are analyzed to extract the following per-pixel properties: hatching level (hatching, cross-hatching, or no strokes), stroke orientation, spacing, intensity, length, and thickness. A mapping is learned from input geometric, contextual and shading features of the 3D object to these hatching properties, using classification, regression, and clustering techniques. Then, a new illustration can be generated in the artist&rsquo;s style, as follows. First, given a new view of a 3D object, the learned mapping is applied to synthesize target stroke properties for each pixel. A new illustration is then generated by synthesizing hatching strokes according to the target properties.</p>
  <p align="justify">&nbsp; </p>

  <a href="MLHatching.pdf"><img style="padding: 0px 30px 10px 10px; float: left;" alt="paper thumbnail" src="ML_Hatching_thumbnail.jpg"></a>
  <h2>Paper</h2>
  <a href="MLHatching.pdf">MLHatching.pdf</a>, 5MB<br>
  <br>
  <h3>Citation</h3>
  <p>Evangelos Kalogerakis, Derek Nowrouzezahrai, Simon Breslav, Aaron Hertzmann, &quot;Learning Hatching for Pen-and-Ink Illustration of Surfaces&quot;,
    <em>ACM Transactions on Graphics, Vol. 31, No. 1, 2012</em> <br>
    <br>
    <a href="ML_Hatching_bib.txt">Bibtex</a> </p>
  <p>&nbsp;</p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
<h2>Presentation</h2>
    <p>Here is the Siggraph 2012 presentation of the paper. <br>
    <a href="MLhatching_web.pdf">PDF version</a>, 3MB </p>
    <p><br>
    </p>
  <h2>Acknowledgements</h2>
  <p>We thank Seok-Hyung Bae, Patrick Coleman, Vikramaditya Dasgupta, Mark Hazen, Thomas Hendry, and Olga Vesselova for creating the hatched drawings. We thank Olga Veksler for the graph cut code and Robert Kalnins, Philip Davidson, and David Bourguignon for the jot code. We thank Aim@Shape, VAKHUN, and Cyberware repositories as well as Xiaobai Chen, Aleksey Golovinskiy, Thomas Funkhouser, Andrea Tagliasacchi and Richard Zhang for the 3D models used in this paper. This project was funded by NSERC, CIFAR, CFI, the Ontario MRI, and KAUST Global Collaborative Research.
 </p>
<div id="footer"><a href="https://kalo-ai.github.io/">back to Evangelos Kalogerakis' page</a></div>
</div>
</body>
</html>
